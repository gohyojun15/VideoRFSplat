---
layout: inner
position: left
priority: 3
categories: "media"

title: "VideoRFSplat: Architecture Overview"
blocks:
    # - video: "https://monst3r-project.github.io/files/teaser_vid_v2_lowres.mp4"
    # - text: "video description"
    - text: "In this work, we improve the joint distribution modeling of multi-view images and camera poses for text-to-3D generation by leveraging video generation models. Previous approaches to direct 3DGS generation for real-world scenes jointly generate multi-view images and diverse camera poses using 2D generative models, eliminating the need for user-specified viewpoints. However, we found that parameter-sharing schemes between these modalities, such as channel concatenation, degrade text-prompt coherence and generation quality. To address this, we propose a dual-stream architecture that integrates a dedicated pose generation model alongside a pre-trained video generation model via communication blocks (see below figure). By generating multi-view images and camera poses in separate streams, our approach minimizes interference between modalities, improving both consistency and fidelity. Then, gaussian splatting decoder based on feedforward 3DGS methods decodes 3DGS from generated multi-view image latents and camera poses."
    - image: "files/overview.png"

---
